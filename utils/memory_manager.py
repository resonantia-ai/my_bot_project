# memory_manager.py
# ï¿½Sï¿½Lï¿½ï¿½ï¿½wï¿½Eragï¿½Eï¿½ï¿½ï¿½wï¿½Eï¿½Û’ï¿½ï¿½wï¿½Eï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ğ“ï¿½ï¿½ï¿½ï¿½ÄAï¿½\ï¿½ï¿½ï¿½vï¿½ï¿½ï¿½ï¿½ï¿½vï¿½gï¿½ğ¶ï¿½


import os
import json
from datetime import datetime
from typing import Any, Dict, List, Optional

from symbolic_reflector import recall_symbolic_memories
from poetic_reflector import generate_poetic_reflection
from aria_journal import log_aria_journal  # ï¿½Ç‰ï¿½

MEMORY_DIR = os.path.abspath("memory")

def load_json(path: str, fallback: Optional[Any] = None) -> Any:
    try:
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception as e:
        print(f"[memory_manager] JSONãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    return fallback if fallback is not None else []

# ï¿½ï¿½ï¿½Sï¿½gï¿½ï¿½ï¿½~ï¿½ï¿½ï¿½O
def safe_trim(text: str, limit: int = 500) -> str:
    """
    æŒ‡å®šæ–‡å­—æ•°ã§å®‰å…¨ã«ãƒˆãƒªãƒ ï¼ˆæ–‡æœ«ã§åˆ‡ã‚‹ï¼‰
    """
    return text if len(text) <= limit else text[:limit].rsplit(".", 1)[0] + "."

# === ï¿½ï¿½ï¿½Cï¿½ï¿½ï¿½\ï¿½ï¿½ï¿½vï¿½ï¿½ï¿½ï¿½ï¿½vï¿½gï¿½\ï¿½z ===
def build_prompt(system_prompt: str, user_input: str) -> List[Dict[str, Any]]:
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆçŸ­æœŸè¨˜æ†¶ãƒ»è±¡å¾´å±¤ãƒ»RAGãƒ»è©©çš„åæ˜ ã‚’çµ±åˆï¼‰
    """
    prompt: List[Dict[str, Any]] = [{"role": "system", "content": system_prompt}]

    # [1] çŸ­æœŸè¨˜æ†¶
    memory = load_json(os.path.join(MEMORY_DIR, "short_term_memory.json"), [])
    prompt.extend(memory)

    # [2] è±¡å¾´å±¤è¨˜æ†¶
    reused = recall_symbolic_memories(user_input)
    for entry in reused:
        content = entry.get("content") or entry.get("text")
        if content:
            prompt.append({
                "role": "assistant",
                "content": f"[Symbolic Echo]\n{content}"
            })

    # [3] RAGè¦ç´„
    rag = load_json(os.path.join(MEMORY_DIR, "rag_summary.json"), {})
    origin = load_json(os.path.join(MEMORY_DIR, "rag_origin_trace.json"), {})
    if isinstance(rag, dict) and isinstance(origin, dict):
        summary = safe_trim(rag.get("summary", ""), limit=500)
        source = origin.get("source", "")
        if summary:
            prompt.append({
                "role": "assistant",
                "content": f"[Knowledge Reference]\n{summary}\n\nå‡ºå…¸: <{source}>"
            })

    # [4] è©©çš„ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
    poetic = generate_poetic_reflection()
    if poetic:
        prompt.append(poetic)

    # [5] ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    prompt.append({"role": "user", "content": user_input})

    # [6] Ariaã‚¸ãƒ£ãƒ¼ãƒŠãƒ«è¨˜éŒ²
    if poetic:
        log_aria_journal(
            summary="Reflection from poetic layer",
            content=poetic["content"],
            topics=rag.get("query", "").split() if "query" in rag else [],
            style="poetic",
            emotion_tags=[],
            source="memory_manager"
        )

    return prompt
